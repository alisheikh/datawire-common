Usage
=====

Start the analyzer: ./analyzer -t

Receive messages from the analyzer:
    ./arc //localhost
    ./arc //localhost/controller

arc commands:

/update <dict>
/update <key:value>

/delete <key>
/delete

/read

Server
======

Engine for receiving, routing, and analyzing AMQP messages for Kinetic.

Control Flow
============


                       [global replication]    [regional replication]

    Client ----> DNS -------> Redirector ----------> Analyzers ----> Alert
                  |               |                      |
                  |               |                      |
            map to vhost    global schema            local schema
           us-west.aws.*   cust <-> analyzer map     git repo

## Network

- routing
  - analyzer --> redirector
  - client --> analyzer (internet)
  - client --> redirector (internet)

- VPC DMZ contains
  - analyzers
  - redirector
  - only allows AMQP traffic on 

## Partioning

Message flow is partitioned in the following hierarchy:

- to region/hosting provider (via DNS vhost, based on customer)
- to analyzer, based on topology and data type

## Redirector / Analyzer Handshake

When an analyzer is instantiated, it initiates a handshake with the
redirector. The handshake protocol:

- notifies the redirector that the analyzer is available, and is
  subsequently used by the redirector for liveness detection
- notifies the redirector of the data sources that it will subscribe
  to, based on the topology information available to the analyzer

System architecture
===================

- Deploy
  - get code
  - build image (or docker container?)
  - create AMI
  - push AMI to amazon

- Redirector instantiates new analyzer VMs

- Analyzer node
  - Skynet: deploys new docker containers and sets up HAProxy config
  - Docker containers running analyzer/custom code
  - HAProxy to proxy from localport to outside world
  - Advanced: packet filtering & monitoring on the stuff 

Security architecture
=====================

Inspiration:

https://www.usenix.org/conference/lisa13/enterprise-architecture-beyond-perimeter

- All point-to-point communications are encrypted with TLS
- We use TLS client certificates for authentication

## Analyzer security

Docker isolates all Python code in its own container. Network access
is limited to localhost. An HAProxy that sits on the actual virtual
machine handles authentication and SSL, and proxies traffic to the
appropriate container. This insures that the container never has
access to the client certificates.

## Machine identity

http://pomcor.com/techreports/M2MSec14.pdf

## Certificate handling

Each machine has its own unique certificate:

- Analyzer VM
- Redirector
- Alert
- ...

When a VM is created, it is issued its own certificate by the Kinetic
certificate server.  (How do you authenticate the Kinetic cert server?)

When a client is created, it is also issued a certificate. 

Certificates are bound to a machine (via IP?).

Do we use RADIUS+EAP?

1. Client will verify server certificate.
2. Server needs to:
   - verify client identity
   - verify authorization (?)


the client certificate will have the CA info

Analyzer:
- can get identity passed in by haproxy

https://raymii.org/s/tutorials/haproxy_client_side_ssl_certificates.html
http://blog.haproxy.com/2012/10/03/ssl-client-certificate-management-at-application-level/

Questions:
 - how do we partition a single data stream (e.g., statsd/AMQP for Duo) across
   multiple analyzers?



Data Architecture
=================

The message header contains, among other things:

- origin
- data type (statsd, collectd, etc.)

The local schema contains, among other things:

- user auth info
- topology info
- info about data sources

User Config
===========

- they need to generate a client-side config
  - AMQP address
  - secret key
  - profile
- alert configuration
  - who to send alerts to
  - specify data sources to apply alerts to
- (optional) analytics
- (optional) topology file

Availability
============

We minimize moving parts to maximize availability.

- Replicate git repo to all filesystems
- Auth TBD

TODO
====

- Create a language to define message topologies
- API key authentication mechanism / general auth mechanism
- Evaluate deploying to both DO and AWS
  - Dogfood and implement alerting
- Define a schema for topology
- Implement alert node (rhs)
  - Processes alert info from analyzer/aggregator
  - Sends out AMQP alerts with context, etc. to AMQP<->SMTP bridge, etc.
  - Alert needs to organize based on topology
  - Status Board
- Need Watchdog (richardl)
- Client certs for authentication (richardl)
- Pull out average function from analyzer code (rhs)
- Redirector supports profiles

Demo Scenario
=============

1. User registers on website.

2. User logs into website, and gets wizard that gives step-by-step
directions on setup.

2a. User sets up statsd to communicate with Kinetic. Includes client
cert, profile, etc.

2b. In website, user sees that the connection is live.

2c. In website, user selects the "cluster analytic". The specific
analytic is going to take the average value from the statsd feed and
alert if the value of any one of the feeds exceeds the average by more
than 1 stddev.
  - metric is a timer on a specific webpage

2d. In website, user configures the analytic & alert:
  - the recipients (email addresses)
  - the deviation amount (e.g., 1 std deviation)
  - the profile and/or data sources to apply the cluster analytics to

2e. In website, user clicks "activate" or something like that.

3a. The alert goes live, and when an anomalous event is detected:
  - email is sent to the user
  - history of alerts is shown on the website
  - TBD: how do we guarantee a test event?
<

=== Control Messages ===

The general format for all control messages is as follows. The message
properties of a control message contain a special entry. The key for
this entry is "opcode" and the value can any string value depending on
what capabilities the service exposes.

Currently analyzers expose three operations "update", "delete", and
"read":

  - The "update" operation expects the message body to be a map and
    will update the analyzer's configuration object based on the
    key/value pairs in the map.

  - The "delete" operation expects a list of keys and will delete
    those keys from the analyzer's config object. A "delete" operation
    with an empty body will delete all keys from the analyzer's config
    object.

  - The "read" operation causes a snapshot of the config object to be
    sent to the address indicated in the reply-to field of the control
    message.

Note that it is not usually necessary to use the "read" operation
explicitly since all subscriptions to the controller will be notified
whenever the configuration is modified.
